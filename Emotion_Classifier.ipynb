{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzFuQqdv9FN"
      },
      "source": [
        "# Emotion Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQV4bHtRwfJ-"
      },
      "source": [
        "## Instalación de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install mediapipe\n",
        "#%pip install imbalanced-learn\n",
        "#%pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHqjcab3v6Rp"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETE_7Yd-wyPU"
      },
      "source": [
        "## Rutas de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUTA_BASE = \"SAMMv3\"\n",
        "TAMAÑO_FINAL = 224\n",
        "\n",
        "MAPEO_EMOCIONES = {\n",
        "    \"Anger\": 0,\n",
        "    \"Contempt\": 1,\n",
        "    \"Disgust\": 2,\n",
        "    \"Fear\": 3,\n",
        "    \"Happiness\": 4,\n",
        "    \"Sadness\": 5,\n",
        "    \"Surprise\": 6\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZWH_1RShKxa"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La función `cargar_imagen` realiza lo siguiente:\n",
        "1. Carga una imagen y la convierte en un arreglo de numpy donde cada pixel se representa como un valor numérico (esto si la imagen está en escala de grises) o como un conjuntos de valores si la imagen es a color.\n",
        "\n",
        "2. Esta imagen se reduce a la mitad de su tamaño original (1/2 resolución) con la función IMREAD_REDUCED_GRAYSCALE_2.\n",
        "\n",
        "\n",
        "Resultado: Imagen procesada como un arreglo de 2 dimensiones (alto, ancho)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cargar_imagen(ruta):\n",
        "    try:\n",
        "        # IMREAD_REDUCED_GRAYSCALE_2 carga en escala de grises la imagen reducida a su mitad. \n",
        "        # Por ejemplo si se carga una imagen de 500x300 el tamaño final sería de 250x150 px.\n",
        "        imagen = cv2.imread(ruta, cv2.IMREAD_REDUCED_GRAYSCALE_2) \n",
        "        if imagen is None:\n",
        "            return None\n",
        "        for escala in [0.25, 0.1]:\n",
        "            try:\n",
        "                return cv2.resize(imagen, (0, 0), fx=escala, fy=escala)\n",
        "            except:\n",
        "                continue\n",
        "        return None\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# recorta y redimensiona una imagen cuadrada para dejarla lista para el modelo\n",
        "def preprocesar_imagen(imagen):\n",
        "    try:\n",
        "        alto, ancho = imagen.shape[:2]\n",
        "        # se toma el lado mas pequeño para cortar el frame en un cuadro \n",
        "        lado = min(alto, ancho)\n",
        "        y = (alto - lado) // 2\n",
        "        x = (ancho - lado) // 2\n",
        "        recorte = imagen[y:y+lado, x:x+lado]\n",
        "        # se redimensiona la imagen recortada al tamaño final deseado (224x224 px)\n",
        "        return cv2.resize(recorte, (TAMAÑO_FINAL, TAMAÑO_FINAL))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def extraer_landmarks(imagen, mallador):\n",
        "    try:\n",
        "        if len(imagen.shape) == 2:\n",
        "            imagen = cv2.cvtColor(imagen, cv2.COLOR_GRAY2RGB)\n",
        "        resultados = mallador.process(imagen)\n",
        "        if resultados.multi_face_landmarks:\n",
        "            return np.array([[p.x, p.y] for p in resultados.multi_face_landmarks[0].landmark])\n",
        "    except:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def normalizar_landmarks(landmarks):\n",
        "    try:\n",
        "        centro = landmarks[1]\n",
        "        landmarks -= centro\n",
        "        escala = np.linalg.norm(landmarks[234] - landmarks[454])\n",
        "        return (landmarks / escala).flatten()\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga de datos y balanceo de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cargar_dataset():\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    mallador = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.3)\n",
        "    datos_por_clase = {}\n",
        "\n",
        "    for emocion, codigo in MAPEO_EMOCIONES.items():\n",
        "        carpeta = os.path.join(RUTA_BASE, emocion)\n",
        "        if not os.path.exists(carpeta):\n",
        "            print(f\"¡Carpeta no encontrada! {carpeta}\")\n",
        "            continue\n",
        "\n",
        "        archivos = [f for f in os.listdir(carpeta) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total = len(archivos)\n",
        "        if total == 0:\n",
        "            continue\n",
        "        if total > 900:\n",
        "            archivos = archivos[:900]\n",
        "\n",
        "        print(f\"Procesando '{emocion}' ({len(archivos)} imágenes)...\")\n",
        "        X_tmp, y_tmp = [], []\n",
        "\n",
        "        for archivo in tqdm(archivos, desc=f\"Procesando {emocion}\"):\n",
        "            ruta = os.path.join(carpeta, archivo)\n",
        "            img = cargar_imagen(ruta)\n",
        "            if img is not None:\n",
        "                img_proc = preprocesar_imagen(img)\n",
        "                if img_proc is not None:\n",
        "                    landmarks = extraer_landmarks(img_proc, mallador)\n",
        "                    if landmarks is not None:\n",
        "                        norm = normalizar_landmarks(landmarks)\n",
        "                        if norm is not None:\n",
        "                            X_tmp.append(norm)\n",
        "                            y_tmp.append(codigo)\n",
        "\n",
        "        if len(X_tmp) < 800 and len(X_tmp) > 0:\n",
        "            print(f\"Aplicando SMOTE para '{emocion}' ({len(X_tmp)} → 800)...\")\n",
        "            X_tmp.append(np.zeros_like(X_tmp[0]))\n",
        "            y_tmp.append(-1)\n",
        "            smote = SMOTE(sampling_strategy={codigo: 800}, random_state=42)\n",
        "            X_res, y_res = smote.fit_resample(X_tmp, y_tmp)\n",
        "            X_tmp = [x for x, yv in zip(X_res, y_res) if yv == codigo]\n",
        "            y_tmp = [codigo] * len(X_tmp)\n",
        "\n",
        "        datos_por_clase[codigo] = (X_tmp, y_tmp)\n",
        "\n",
        "    mallador.close()\n",
        "    X, y = [], []\n",
        "    for Xc, yc in datos_por_clase.values():\n",
        "        X.extend(Xc)\n",
        "        y.extend(yc)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXS1QFcOhYtq"
      },
      "source": [
        "## Entrenar y evaluar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entrenar_modelo(X, y):\n",
        "    modelo = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced')\n",
        "    )\n",
        "    modelo.fit(X, y)\n",
        "    return modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtener modelo entrenado y guardarlo en un pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ejecucion\n",
        "print(\"=== CARGANDO DATASET ===\")\n",
        "X, y = cargar_dataset()\n",
        "print(f\"\\nTotal de muestras: {len(X)}\\nDistribución final:\", Counter(y))\n",
        "\n",
        "print(\"\\n=== VALIDACIÓN CRUZADA ===\")\n",
        "pipeline = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced'))\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "acc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "f1_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='f1_macro')\n",
        "print(f\"Accuracy promedio: {acc_scores.mean():.4f}\")\n",
        "print(f\"F1 macro promedio: {f1_scores.mean():.4f}\")\n",
        "\n",
        "print(\"\\n=== ENTRENAMIENTO FINAL ===\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=21)\n",
        "modelo = entrenar_modelo(X_train, y_train)\n",
        "\n",
        "print(\"\\n=== GUARDANDO MODELO ===\")\n",
        "joblib.dump(modelo, \"modelo_emociones.pkl\")\n",
        "print(\"Modelo guardado como 'modelo_emociones.pkl'\")\n",
        "\n",
        "print(\"\\n=== EVALUACIÓN ===\")\n",
        "y_pred = modelo.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=MAPEO_EMOCIONES.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocesar_imagen(imagen):\n",
        "    try:\n",
        "        alto, ancho = imagen.shape[:2]\n",
        "        lado = min(alto, ancho)\n",
        "        y = (alto - lado) // 2\n",
        "        x = (ancho - lado) // 2\n",
        "        recorte = imagen[y:y+lado, x:x+lado]\n",
        "        return cv2.resize(recorte, (224, 224))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def extraer_landmarks(imagen):\n",
        "    try:\n",
        "        mp_face_mesh = mp.solutions.face_mesh\n",
        "        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.3) as mallador:\n",
        "            if len(imagen.shape) == 2:\n",
        "                imagen = cv2.cvtColor(imagen, cv2.COLOR_GRAY2RGB)\n",
        "            resultados = mallador.process(imagen)\n",
        "            if resultados.multi_face_landmarks:\n",
        "                return np.array([[p.x, p.y] for p in resultados.multi_face_landmarks[0].landmark])\n",
        "    except:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def normalizar_landmarks(landmarks):\n",
        "    try:\n",
        "        centro = landmarks[1]\n",
        "        landmarks -= centro\n",
        "        escala = np.linalg.norm(landmarks[234] - landmarks[454])\n",
        "        return (landmarks / escala).flatten()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def predecir_emocion(ruta_imagen):\n",
        "    # 1. Cargar imagen original sin procesar (color, tal cual está)\n",
        "    img_original = cv2.imread(ruta_imagen, cv2.IMREAD_COLOR)\n",
        "    if img_original is None:\n",
        "        print(\"No se pudo cargar la imagen original.\")\n",
        "        return\n",
        "\n",
        "    # 2. Cargar versión reducida para procesamiento\n",
        "    img = cargar_imagen(ruta_imagen)  # esta sí puede ser reducida y en gris\n",
        "    if img is None:\n",
        "        print(\"No se pudo cargar la imagen para análisis.\")\n",
        "        return\n",
        "\n",
        "    img_proc = preprocesar_imagen(img)\n",
        "    if img_proc is None:\n",
        "        print(\"No se pudo procesar la imagen.\")\n",
        "        return\n",
        "\n",
        "    landmarks = extraer_landmarks(img_proc)\n",
        "    if landmarks is None:\n",
        "        print(\"No se detectaron landmarks.\")\n",
        "        return\n",
        "\n",
        "    landmarks_visuales = landmarks.copy()\n",
        "    norm_landmarks = normalizar_landmarks(landmarks)\n",
        "    if norm_landmarks is None:\n",
        "        print(\"No se pudo normalizar la imagen.\")\n",
        "        return\n",
        "\n",
        "    pred = modelo.predict([norm_landmarks])[0]\n",
        "    emocion = MAPEO_EMOCIONES_INV[pred]\n",
        "\n",
        "    # 3. Imagen con landmarks\n",
        "    img_color = cv2.cvtColor(img_proc.copy(), cv2.COLOR_GRAY2BGR)\n",
        "    h, w = img_proc.shape[:2]\n",
        "\n",
        "    for punto in landmarks_visuales:\n",
        "        x = int(punto[0] * w)\n",
        "        y = int(punto[1] * h)\n",
        "        if 0 <= x < w and 0 <= y < h:\n",
        "            cv2.circle(img_color, (x, y), 2, (0, 255, 0), -1)\n",
        "\n",
        "    # 4. Convertir para visualización con matplotlib\n",
        "    img_original_rgb = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
        "    img_con_landmarks = cv2.cvtColor(img_color.copy(), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 5. Mostrar ambas imágenes\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_original_rgb)\n",
        "    plt.title(\"Original (sin procesar)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_con_landmarks)\n",
        "    plt.title(f\"Predicción: {emocion}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pruebas\n",
        "predecir_emocion(\"pruebas/p1.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predecir_emocion(\"pruebas/p2.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predecir_emocion(\"pruebas/p3.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predecir_emocion(\"pruebas/p4.jpg\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predecir_emocion(\"pruebas/p5.jpg\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predecir_emocion(\"pruebas/p6.jpg\") "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
